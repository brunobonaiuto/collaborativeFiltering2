{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the collaborative filtering using deep learning\n",
    "* Randomly Initialise Parameters — these will be the latent factors that help predict whether someone will like a movie.\n",
    "* Calculate Predictions — this is done by taking the matrix dot product of the movie and user matrices. An example would be if a user’s likening to international films is high, and a movie is foreign; the product of the two will be large and, that movie will rank higher for that user.\n",
    "* note: This approach could be used for prediction but is very inefficient as it requires a vector to be created and stored for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libreries\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "from fastai import *\n",
    "#from fastbook import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>160341</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Bloodmoon (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>160527</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Sympathy for the Underdog (1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>160836</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hazard (2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>163937</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Blair Witch (2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>163981</td>\n",
       "      <td>3.5</td>\n",
       "      <td>31 (2016)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating                             title\n",
       "100831     610   160341     2.5                  Bloodmoon (1997)\n",
       "100832     610   160527     4.5  Sympathy for the Underdog (1971)\n",
       "100833     610   160836     3.0                     Hazard (2005)\n",
       "100834     610   163937     3.5                Blair Witch (2016)\n",
       "100835     610   163981     3.5                         31 (2016)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing directly the confusion matrix\n",
    "user_features_df = pd.read_csv('/home/bbruno/all_here/python course/thesis/knn/user_features_df.csv')\n",
    "user_features_df\n",
    "\n",
    "#importing the user,movie,rating dataframe\n",
    "#we drop a column that was added by mistake by the system\n",
    "df = pd.read_csv('/home/bbruno/all_here/python course/thesis/knn/df.csv').drop('Unnamed: 0', axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>547</td>\n",
       "      <td>Brazil (1985)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>You, Me and Dupree (2006)</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328</td>\n",
       "      <td>Slumdog Millionaire (2008)</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace (1999)</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shadowlands (1993)</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>288</td>\n",
       "      <td>Mimic (1997)</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>477</td>\n",
       "      <td>Scott Pilgrim vs. the World (2010)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>385</td>\n",
       "      <td>Hoop Dreams (1994)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>469</td>\n",
       "      <td>Superman II (1980)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>Junior (1994)</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we create a dataloader\n",
    "#we pass the title of the movie and not the movie id\n",
    "dls = CollabDataLoaders.from_df(df, user_name='userId',item_name='title', bs=64)\n",
    "#we can see the batch\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE PREDICTIONS USING MATRIX MULTIPLICATION\n",
    "\n",
    "#we create a matrix with the user features\n",
    "n_users = len(dls.classes['userId']) #the number of user is the lenght of how many users\n",
    "#we create a matrix with the movie features\n",
    "n_movies = len(dls.classes['title']) #the number of movies is the lenght of how many movies\n",
    "#we choose the number of factors\n",
    "n_factors = 5 \n",
    "\n",
    "#we create a random matrix with the user features(embeddings)\n",
    "#userFactors = (numberOfUsers x 5)\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "#we create a random matrix with the movie features(embeddings)\n",
    "#movieFactors = (numberOfMovies x 5)\n",
    "movie_factors = torch.randn(n_movies, n_factors)\n",
    "\n",
    "##########################################\n",
    "#To calculate the result for a particular movie and user combination, \n",
    "#we have to look up the index of the movie in our movie latent factor matrix and\n",
    "#the index of the user in our user latent factor matrix; \n",
    "#then we can do our dot product between the two latent factor vectors\n",
    "\n",
    "# Create a function that takes the user id and the movie title to make a prediction\n",
    "def oneHotPredict(userId, title):\n",
    "    '''In the oneHotPredict function, \n",
    "    we use the indices of the user and movie in the embedding matrices\n",
    "    to look up the corresponding embeddings.\n",
    "    ----\n",
    "    We calculate the prediction by taking the dot product\n",
    "    (element-wise multiplication and then sum) of the user and movie embeddings.\n",
    "    '''\n",
    "    userIdx = dls.classes['userId'].o2i[userId]\n",
    "    movie_idx = dls.classes['title'].o2i[title]\n",
    "    \n",
    "    user_embedding = user_factors[userIdx]\n",
    "    movie_embedding = movie_factors[movie_idx]\n",
    "    \n",
    "    prediction = (user_embedding * movie_embedding).sum()\n",
    "    return print(f\"Predicted rating for user '{userId}' and '{title}': {prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user '10' and 'Slumdog Millionaire (2008)': 0.75\n"
     ]
    }
   ],
   "source": [
    "# Prediction for user 9 and the movie 'Toy Story (1995)'\n",
    "prediction = oneHotPredict(10, 'Slumdog Millionaire (2008)')\n",
    "#print(f'Predicted rating for user 9 and Toy Story (1995): {prediction:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization\n",
    "* A better approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params(size):\n",
    "    \"\"\"\n",
    "      Pass tensor shape\n",
    "      Returns normalised model parameters\n",
    "    \"\"\"\n",
    "    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))\n",
    "\n",
    "class DotProductBias(Module):\n",
    "    \"\"\"\n",
    "    Model architecture for collaborative filtering\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0, 5.5)):\n",
    "        \"\"\"\n",
    "        Initialises model with parameters\n",
    "        :param n_users: number of users\n",
    "        :param n_movies: number of movies\n",
    "        :param n_factors: number of factors\n",
    "        :param y_range: sigmoid limit\n",
    "        \"\"\"\n",
    "        self.user_factors = create_params([n_users, n_factors])\n",
    "        self.user_bias = create_params([n_users])\n",
    "        self.movie_factors = create_params([n_movies, n_factors])\n",
    "        self.movie_bias = create_params([n_movies])\n",
    "        self.y_range = y_range\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Applies a forward pass on the dataset passed\n",
    "        :param x: data as DataLoaders obj\n",
    "        :return: predictions in sigmoid range (tensor)\n",
    "        \"\"\"\n",
    "        users = self.user_factors[x[:, 0]]\n",
    "        movies = self.movie_factors[x[:, 1]]\n",
    "        res = (users*movies).sum(dim=1)\n",
    "        res += self.user_bias[x[:, 0]] + self.movie_bias[x[:, 1]]\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.814713</td>\n",
       "      <td>0.800907</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705350</td>\n",
       "      <td>0.735490</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541343</td>\n",
       "      <td>0.708501</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.401168</td>\n",
       "      <td>0.705881</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292267</td>\n",
       "      <td>0.705909</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "#wd = weight decay (L2 regularization)\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies:\n",
      "Guarding Tess (1994)\n",
      "Toy Story 2 (1999)\n",
      "10 (1979)\n",
      "In Like Flint (1967)\n",
      "Ladder 49 (2004)\n"
     ]
    }
   ],
   "source": [
    "#import torch.nn as nn\n",
    "#Recommendations\n",
    "def recommends(fav_movie, top_n=5):\n",
    "    movie_factors = learn.model.movie_factors\n",
    "    #we look up the movie in the movie factors\n",
    "    idx = dls.classes['title'].o2i[fav_movie]\n",
    "    #find the movie with minimum distance\n",
    "    distances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
    "    #we sort the movies by distance\n",
    "    idx = distances.argsort(descending=True)[1:top_n+1]\n",
    "    #we return the movies\n",
    "    recommended_movies = [dls.classes['title'][i] for i in idx]\n",
    "    return recommended_movies\n",
    "\n",
    "recommended_movies = recommends('Toy Story (1995)')\n",
    "print(\"Recommended movies:\")\n",
    "for movie in recommended_movies:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user '10' and '10 (1979)': 2.96\n",
      "Predicted rating for user '25' and 'Toy Story (1995)': 4.67\n"
     ]
    }
   ],
   "source": [
    "#def prediction for a user\n",
    "def prediction_user_like(userId, title):\n",
    "    userIdx = dls.classes['userId'].o2i[userId]\n",
    "    movie_idx = dls.classes['title'].o2i[title]\n",
    "\n",
    "    # Make a prediction using the model's forward method\n",
    "    prediction = learn.model.forward(tensor([[userIdx, movie_idx]])).item()\n",
    "\n",
    "    return print(f\"Predicted rating for user '{userId}' and '{title}': {prediction:.2f}\")\n",
    "\n",
    "prediction = prediction_user_like(10, '10 (1979)')\n",
    "prediction = prediction_user_like(25, 'Toy Story (1995)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
